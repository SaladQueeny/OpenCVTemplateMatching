#      1.	Постановка задачи
      
Разработать и реализовать перспективное преобразование средствами СТЗ.
1.	Установить необходимое программное обеспечение и библиотеки
2.	Придумать и сделать метки для дальнейшего их поиска 
3.	Написать функцию для поиска необходимых меток и сохранения их координат
4.	В отдельной функции по сохраненным координатам сделать перспективное преобразование
5.	Пункты с 2 по 4 реализовать в режиме реального времени.
 
# 2.	Решение задачи
## 2.1.	Установка ПО и необходимых библиотек
Выполнять данное задания я буду в Visual Studio 2019 на языке c++ с использованием библиотек opencv 4, так как до прохождении практики я уже работал с этой средой программирования и с библиотеками opencv для языка c++.

![image](https://user-images.githubusercontent.com/70723969/132224990-45dbeb99-c057-46d2-a2db-a4cd183fa526.png)

Рис.1. Интерфейс Visual Studio 2019 с правильно подключенными библиотеками opencv 4.

## 2.2.	Создание меток
Первоначальная идея поиска меток была довольна проста – шаблонный поиск, однако в дальнейшем она может поменяться из-за неэффективности, поэтому для него была необходима максимально необычная форма меток, которая отличалась бы от множества фигур на видео, поэтому было 2 варианта меток:

![image](https://user-images.githubusercontent.com/70723969/132225830-e32ebeaa-1f4e-4fe9-9838-6e40984860ea.png)   

Рис. 2. Первый вариант метки 

![image](https://user-images.githubusercontent.com/70723969/132225864-dbd8a26a-d6f7-436a-b532-fa41814db268.png)

Рис. 3. Второй вариант метки

Второй вариант метки показал себя лучше, поэтому в дальнейшем он был выбран как основной.

## 2.3.	Функция для поиска необходимых меток и сохранение их координат
Для поиска необходимых меток был выбрал шаблонный поиск, так как он довольно прост в своей реализации. Функция matchTemplate сравнивает исходное изображение и шаблон и на выходе мы получаем черно-белое изображение с максимально светлыми или максимально тёмными точками. Эти точки и есть место совпадения шаблона с изначальным изображением. Координаты этих точек можно найти с помощью функции minMaxLoc. Мной был выбран метод нахождения совпадений TM_CCOEFF_NORMED, так как он находит не максимально точное совпадение, а усредненные совпадения с шаблоном и результат сразу нормирует, что больше подходит для моих целей.
Пример нахождения объектов с помощью шаблонного поиска:
 
 ![image](https://user-images.githubusercontent.com/70723969/132225993-f96166ac-69bd-4215-8792-75ba9ff28d73.png)
 
Рис. 4. Изначальное изображение
 
 ![image](https://user-images.githubusercontent.com/70723969/132226007-12db4f8f-60d5-4769-8a6f-4825a5afcd72.png)

Рис. 5. Изображение, полученное после выполнения функции matchTemplate

Для того, чтобы отметить все наши совпадения необходимо после нахождения следующего совпадения закрашивать уже найденную область и идти на следующую, пока существуют области с совпадением. 

Однако такой способ не давал точных результатов и приходилось фильтровать найденные координаты, сравнивая из с предыдущими следующим способом:
if ((abs(point.x – prev_point.x) > 5) || (abs(point.y – prev_point.y) > 5)) {
Если модуль разности координат предыдущей и текущей точки по каждой из координат больше 5, то мы эту точку добавляем, иначе идём дальше и пропускаем данную точку, так как она является дубликатом предыдущей точки. 
После фильтрации ненужных точек получилось 4 совпадения, которые обведены прямоугольником с отмеченными координатами и это показано на следующем рисунке.
 
 ![image](https://user-images.githubusercontent.com/70723969/132226036-6a2efb50-8f90-4f6e-bb96-bc6e6a75307a.png)

Рис. 6. Исходное изображение с отмеченными совпадениями шаблона
К сожалению, такой хороший и точный результат не всегда получается, ведь любое изменение угла поворота метки или увеличение её приводит к потере метки. 
 
 ![image](https://user-images.githubusercontent.com/70723969/132226040-2054aa9e-554e-48a5-99a0-33e23847651a.png)

Рис. 7. Пример потери увеличенной метки.

Также даже несильное изменение освещения меток, по сравнению с шаблоном приводит к их потере, поэтому было принято решение отказаться от шаблонного поиска в пользу поиска фигур по их контурам с помощью аппроксимации. 

Был разработан алгоритм для нахождения новых меток. Новыми метками стали треугольники, так как это довольно редкая геометрическая фигура.

![T3](https://user-images.githubusercontent.com/70723969/132226114-bbdc19ea-8a5b-4e88-95cc-ab4bf123a9dc.jpg)

Рис. 8. Новая треугольная метка.

Алгоритм определения метки:
1.	Перевод изображения в чёрно-белый формат
2.	Размытие изображения с помощью блюра функцией Гаусса для сглаживания неровностей
3.	Применить детектор границ Канни 
4.	Расширить полученные контуры для избавления от лишних маленьких контуров.
5.	Найти контуры
6.	Аппроксимировать их и найти среди контуров треугольники.

 После реализации данного алгоритма, на экран мы получали отмеченные треугольники и знали их параметры.
Координаты найденных треугольников сохраним для дальнейшего использования

 ![image](https://user-images.githubusercontent.com/70723969/132226208-cd241789-5afe-4db4-a67c-bfa3b0f93420.png)

Рис. 9. Изначальное изображение с новыми метками.

 ![image](https://user-images.githubusercontent.com/70723969/132226352-b9e65fa9-bc41-47d9-807a-1792ec752ff5.png)

Рис. 10. Изображение с подсвеченными метками.

## 2.4.	Перспективное преобразование
Перспективное преобразование необходимо нам для “поворота” изображения прямо на наблюдателя. Пример показан на рисунке ниже, где правое изображение – это исходное изображение, а изображение слева получено с помощью перспективного преобразования.
 
 ![image](https://user-images.githubusercontent.com/70723969/132226364-5e030327-fd91-4f48-bc07-9a50e761457e.png)

Рис. 11. Общий пример перспективного преобразования.

Для перспективного преобразования необходимо найти 2 массива точек, один содержит координаты исходного четырёхугольника, второй содержит координаты соответствующих вершин четырехугольника на необходимом изображении и после применения функции мы получим матрицу для трансформации текущего изображения в «повернутое». Для примера с рисунка 11 первый массив будет {A, B, C, D}, второй массив будет {(0,0),(max(AB, DC), 0),( max(AB, DC), max(AD, BC)),(0, max(AD, BC) )}.
Пример перспективного преобразования для наших меток можно увидеть на рисунке 12.
 
 ![image](https://user-images.githubusercontent.com/70723969/132226372-0b6ee3a4-2875-4396-b5c2-4b5e5441a468.png)

Рис. 12. Изначальное изображение с помеченными центрами.

 ![image](https://user-images.githubusercontent.com/70723969/132226380-56bc1d27-4e88-4381-bde3-da8baf8b2424.png)

Рис. 13. Изображение после перспективного преобразования.

# 3.	Результаты
Для результатов были проведены тесты с подключением к ip-camera на тестовом стенде в ЦНИИ РТК. Результаты приведены на рисунках снизу.
 
 ![image](https://user-images.githubusercontent.com/70723969/132226404-8bd6afca-82ba-4c77-a21f-82621656f792.png)

Рис. 14. Изображение после перспективного преобразования.
 
 ![image](https://user-images.githubusercontent.com/70723969/132226408-08bff29c-b3eb-4f9d-90cc-168749468381.png)

Рис. 15. Изображение после перспективного преобразования.

 ![image](https://user-images.githubusercontent.com/70723969/132226417-aa0059f8-57ec-484f-b138-a7d7799b1c81.png)

Рис. 16. Изображение после перспективного преобразования.

После результатов тестов видно, что программа работает правильно, значит работа выполнена успешно.
